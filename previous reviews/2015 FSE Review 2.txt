Review 2
Review
Summary and evaluation: 	

As specifications are often incomplete, automatic tradespace analysis can be rather useful for guiding design decisions not constrained by specifications. Previous recent work by some of the authors has explored that, especially in the object-relational mapping domain (ORM), by implementing such tools and evaluating how they could lead to designs that are better (for example, show better performance) than the ones provided by ORM frameworks. This paper builds on that by formalising and implementing an automatic tradespace analysis framework that can help the development of tradespace analysis tools. This framework is instantiated for the ORM domain, mainly by adapting an implementation explored in previous work. The main contribution is stronger evidence that such tools can be useful. This is obtained by running the framework instantiation and comparing its results with database schema designs generated by ORM implementations of two popular web development frameworks: Django and Rails.

I like the idea of automatic tradespace analysis, and the overall vision presented in the introduction. I also believe that the framework can be quite useful (is it available somewhere?), even considering that it doesn’t seem to offer much functionality. It has an elegant structure and is well described (although notation and formatting issues makes it hard to read). The framework instantiation and the ORM experiment are also interesting. However, part of that is not new, and part is new but is more of an engineering contribution. The main contribution, and scientific novelty, is the evidence provided by the experiments. But that is also rather incremental (a similar kind of dynamic tradespace analysis evaluation was recently reported in another paper). So I was expecting a more thorough assessment of the experiment results, going beyond the presented numbers and better assessing and explaining the results. For example, in some cases the tradespace analysis results are the same as the ones provided by Django and Rails. Is that supposed to be the case for any model without inheritance? Why? In other cases, the tradespace analysis results are impressively much better than the ones provided by Django and Rails. Why that is the case? What’s so different in the generated schemas? Doesn’t that reflect bias in the applied measurement functions? Doesn’t Django and Rails rely on implicit constraints that are not in the models but that are needed for assuring the correctness of some of the operations that they offer (supposedly, people are not using such frameworks just for the ORM functionality)?

Although I like most of the introduction, after reading the paper it feels like being somewhat disconnected from the rest of the paper. The same applies for the title, which is somewhat broader than what is actually presented in the paper. The paper has too many typos and needs to be carefully revised.

Please find below typos and more specific comments.

Page 1 "Software developers and tools often make a tacit assumption that system analysis yields specifications that are complete with respect to all important system properties.": Who actually does that? In many cases there is no specification!

Page 2 "The problem that we address in this paper is that the software and systems engineering fields have not yet developed fully satisfactory concepts, tools, processes and relationships for engineering systems with incomplete specifications.": OK, but rather vague

Page 2 "also changes the the implementation": also changes the implementation

Page 2 "The first is to articulate the full set of system property dimensions of interest, even if validated specifications cannot practically be given in some of them. The second is to define implementation models and measurement or estimation functions over such representations for these underspecified dimensions. This is a challenge, as our science of system properties and measurement is highly underdeveloped. The third is to make design space exploration and tradeoff analysis an integral part of design. The fourth is to accept that peer rather than hierarchical relationships are needed between systems and software engineers. The fifth is the need to balance the costs of producing more complete specifications against the costs of more coupled designs and against the opportunity costs of premature narrowing of search and adaptation spaces. We also need better tools and methods. Finally, we need to recognize and carefully evaluate throw-a-dart development: producing point solutions from incomplete specifications in hopes that the results will be good. They often aren’t.": How is that done nowadays? It would help to better motivate and better characterise the associated problems. In agile development, for example, how does that relate to the role of informal unplanned communication, deciding about how much testing is needed, measuring by testing, having no specification, etc. What are the consequences of that?

Page 2 "Our overall hypothesis is that a tradespace approach tends to produce results than are significantly better than those produced produced by widely use ORM tools, many of which implement throw-a-dart assumptions.": Please revise, produced twice

Page 2 "The main contribution of this work is a set of experiments the results of which strongly support of this hypothesis.": Please revise

Page 3 "such an approach to significant improve”: significantly

Page 3 "1) An Alloy-based ORM domain specification language; 2) an Alloy-based synthesizer to generate candidate designs; 3) test loads for (Insert and Select SQL scripts) to be executed to dynamic analyze database designs; 4) two kinds of measurement functions (Time and Space measurement functions) to measure time and space tradeoff; 5) a triple of insertion time, retrieval time, and space consumption as a group of analysis result ; 6) a Pareto-optimal filter to filter out non-Pareto-optimal designs.": How is that different from previous work? Is it just fitting existing stuff to the framework?

Page 3 "Early attempts revealed subtle errors in our Alloy-encoded rules for mapping ORM specifications to satisfying solutions": As in the ICSE 2014 paper?

Page 4 "Some of the key functions of the system include": Repetitive

Page 4 "is a function that take a list of": is a function that takes a list of

Page 4 "Figure 2,": Should be better explained before explaining the Trademaker class

Page 5: The formalization is not complex, but it is hard to read due to formatting and notation details.

Page 6 "Our instance for ORM analysis of this framework is produced with the following parameters.": It is not clear here how much of the instantiation comes from previous work. The explanation that appears later could be moved here.

Page 6 "First, for each of the five data models, we wrote database specifications using Django and Rails respectively, and with our formal domain-specific object-modelling language. Second, we synthesized database schemas from these object models along with test loads for dynamic analysis. Third, we populated the synthesized databases by subjecting them to test loads while collecting time and space performance data, and we simply searched for the databases produced by Django and Rails among the synthesizes solutions to determine the properties of the designs produced by these tools.": Please explain here, not later, how this goes beyond the previously published dynamic analysis

Page 6 "as a subject. a document management system built at": Please revise

Page 6 "When we use the Alloy Analyzer to synthesis queries": Please revise. I thought that schemas were synthesized, not queries. Please explain.

Page 6 "In addition to synthesizing test data using Alloy, as indicated we have also hand-crafted a simple data load generator.": Please see previous comment and explain.

Page 6 "To speed the task, we set up a 16-node Spark clusterusing old computers as a back-end analysis platform.": Too many typos, not reporting others. Please carefully revise the paper.

Page 7 "The data we collect include execution times.": How many times each script/query is executed? Do you collect single execution times? or the average time of a number of executions?

Page 7 "the improvement in analysis process that our automated dynamic analysis tool benefits, comparing to manually analysis we adopted in previous work.": That is kind of obvious, and mostly an engineering effort

Page 7 "The most interesting point is that both of two dots are far from the Pareto fronts.": The results are impressive, but could you explain the differences in the synthesized schema with better performance and the schemas generated by Rails and Django? Couldn't it be the case that the synthesized schemas are not good for operations often applied by these web frameworks but not by the scripts in your evaluation data?

Why so few points in the figures for the first model?

Page 7 "For the other four models, Django and Rails create the same schemas, and in three of them, the database defined by Django and Rails are far off the Pareto front.": Why the schemas are the same for the flagship model?

Page 10 "For the Flagship Docs model, Ruby on Rails and Django produced designs equal to ours in performance. We have ascertained that the reason is that the Flagship Docs data model has no inheritance relationship, so all of the objects in the object model are mapped as an independent tables in synthesized database schemas.": Should we expect no gain when there is no inheritance?

Page 11 Please check problems in reference 3 and others.


Strengths and weaknesses: 	+ Interesting ideas

- Superficial analysis of the obtained results

- Incremental, small delta in relation to previous work

- Needs careful revision for typos and other minor issues